# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_TEMPERATURE=0.3

# === TOKEN LIMITS BY MODE ===
# Лимиты для разных режимов редактирования
# ПЛАН (режим 1): структурированный список 5-7 пунктов
PLAN_MAX_TOKENS=300

# РЕДАКТИРОВАНИЕ ФРАГМЕНТА (режим 3): одиночный фрагмент текста
FRAGMENT_MAX_TOKENS=1200

# РЕДАКТИРОВАНИЕ ПОЛНОГО ТЕКСТА (режим 2): весь текст статьи
FULLTEXT_MAX_TOKENS=2400

# === TRUNCATION HANDLING ===
# Автоматические повторы при обрезании ответа (finish_reason=length)
RETRY_ON_TRUNCATION=1
# Множитель для увеличения лимита при retry (если ответ был обрезан)
RETRY_TOKEN_MULTIPLIER=2

# === CHUNKING PARAMETERS ===
# Целевой размер одного чанка в символах (разбиение по абзацам)
CHUNK_TARGET_CHARS=1200

# Максимальный размер одного чанка (если абзац больше, разбивается по предложениям)
CHUNK_MAX_CHARS=2500

# Размер контекстного окна вокруг чанка (для связности)
# Берётся сколько символов до и после чанка из соседних абзацев
CONTEXT_WINDOW_CHARS=400

# === СТРУКТУРНАЯ ВАЛИДАЦИЯ (режим edit-fragment) ===
# Включить пост-валидацию структуры (подсчёт абзацев) для режима fragment
ENABLE_STRUCTURE_VALIDATION=true

# Количество retry'ей при неправильной структуре (например, не совпадает количество абзацев)
STRUCTURE_VALIDATION_RETRIES=1

# Максимальное увеличение токенов при структурном retry (обычно меньше, чем truncation retry)
# Например: 1.3 означает увеличить на 30% (но не менее FRAGMENT_MAX_TOKENS)
STRUCTURE_RETRY_TOKEN_MULTIPLIER=1.3

# === DEBUG & LOGGING ===
# Ключевые события логируются с указанием finish_reason, usage, количества чанков
# Логирование происходит на уровне DEBUG - все детали видны в логах
DEBUG_CHUNKING=true
