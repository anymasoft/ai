#!/usr/bin/env python3
"""
Простой тестовый скрипт для функции sanitize_fragment
(не требует OpenAI API и других зависимостей)
"""

import re

def sanitize_fragment(text: str) -> str:
    """
    Жесткая санитизация результата LLM для удаления маркеров [ФРАГМЕНТ_НАЧАЛО] и [ФРАГМЕНТ_КОНЕЦ].

    Алгоритм:
    1. Если текст содержит ОБА маркера - извлекает содержимое МЕЖДУ ними
    2. Удаляет все отдельные вхождения маркеров (с пробелами/переводами строк)
    3. Триммит только внешние переводы строк

    Args:
        text: Текст для санитизации

    Returns:
        Очищенный текст без маркеров
    """
    if not text:
        return text

    # Попытка 1: Если есть ОБА маркера - извлечь содержимое между ними
    # Используем неж модификатор для поиска между маркерами
    begin_marker = "[ФРАГМЕНТ_НАЧАЛО]"
    end_marker = "[ФРАГМЕНТ_КОНЕЦ]"

    if begin_marker in text and end_marker in text:
        # Найти позиции маркеров
        begin_pos = text.find(begin_marker)
        end_pos = text.find(end_marker)

        if begin_pos < end_pos:
            # Извлечь содержимое между маркерами
            content = text[begin_pos + len(begin_marker):end_pos]
            print(f"[SANITIZE] Найдены ОБА маркера. Извлекаю содержимое между ними.")
            text = content

    # Попытка 2: Удалить любые отдельные вхождения маркеров
    # Включаем пробелы и переводы строк вокруг маркеров
    text = re.sub(r'\s*\[ФРАГМЕНТ_НАЧАЛО\]\s*', '', text)
    text = re.sub(r'\s*\[ФРАГМЕНТ_КОНЕЦ\]\s*', '', text)

    # Триммить только внешние переводы строк (не внутренние!)
    text = text.strip('\n').strip()

    # Если результат пустой - вернуть оригинальный текст для дальнейшего анализа
    if not text.strip():
        print(f"[SANITIZE] После санитизации текст пустой! Возвращаю оригинальный.")
        return text

    return text


def test_sanitize():
    """Запустить мини-тесты"""
    print("=" * 60)
    print("МИНИ-ТЕСТЫ ФУНКЦИИ SANITIZE_FRAGMENT")
    print("=" * 60)

    test_cases = [
        (
            "[ФРАГМЕНТ_НАЧАЛО]\nЭто текст\n[ФРАГМЕНТ_КОНЕЦ]",
            "Это текст",
            "Базовый случай: текст между маркерами"
        ),
        (
            "[ФРАГМЕНТ_НАЧАЛО]\nПервая строка\nВторая строка\n[ФРАГМЕНТ_КОНЕЦ]",
            "Первая строка\nВторая строка",
            "Многострочный текст между маркерами"
        ),
        (
            "[ФРАГМЕНТ_НАЧАЛО]\nТекст\n[ФРАГМЕНТ_КОНЕЦ]\n\nДополнительный текст",
            "Текст",
            "Маркеры с текстом после них"
        ),
        (
            "Текст\n[ФРАГМЕНТ_НАЧАЛО]\nФрагмент\n[ФРАГМЕНТ_КОНЕЦ]",
            "Фрагмент",
            "Маркеры с текстом до них"
        ),
        (
            "Просто текст без маркеров",
            "Просто текст без маркеров",
            "Текст без маркеров"
        ),
        (
            "[ФРАГМЕНТ_НАЧАЛО] Текст [ФРАГМЕНТ_КОНЕЦ]",
            "Текст",
            "Маркеры с пробелами вокруг"
        ),
        (
            "[ФРАГМЕНТ_НАЧАЛО]Текст без переводов[ФРАГМЕНТ_КОНЕЦ]",
            "Текст без переводов",
            "Маркеры без переводов строк"
        ),
        (
            "[ФРАГМЕНТ_НАЧАЛО]\n[ФРАГМЕНТ_КОНЕЦ]",
            "",
            "Пустое содержимое между маркерами"
        ),
    ]

    passed = 0
    failed = 0

    for i, (input_text, expected, description) in enumerate(test_cases, 1):
        result = sanitize_fragment(input_text)
        status = "✓ PASS" if result == expected else "✗ FAIL"

        print(f"\nТест {i}: {description}")
        print(f"Статус: {status}")

        if result != expected:
            print(f"  Input:    {repr(input_text)}")
            print(f"  Expected: {repr(expected)}")
            print(f"  Got:      {repr(result)}")
            failed += 1
        else:
            passed += 1

    print("\n" + "=" * 60)
    print(f"РЕЗУЛЬТАТЫ: {passed} успешно, {failed} ошибок из {len(test_cases)} тестов")
    print("=" * 60)

    return failed == 0


if __name__ == "__main__":
    success = test_sanitize()
    exit(0 if success else 1)
